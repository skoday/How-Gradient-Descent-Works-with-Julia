{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1251a4e-f021-4e2d-b0e4-1bea396b4e52",
      "metadata": {
        "id": "b1251a4e-f021-4e2d-b0e4-1bea396b4e52"
      },
      "source": [
        "# Gradiente Desendente\n",
        "\n",
        "El gradiente descendente es un algoritmo de optimización utilizado en el aprendizaje automático y la optimización matemática para encontrar el mínimo de una función.  \n",
        "Funciona mediante la iteración en la dirección del gradiente negativo de una función para encontrar el mínimo local o global.  \n",
        "Este método ajusta iterativamente los parámetros de un modelo matemático para minimizar una función de pérdida.\n",
        "Hay diferentes variantes del gradiente descendente, como el gradiente descendente estocástico (SGD), el gradiente descendente por lotes, el mini-batch gradient descent, entre otros, que se adaptan a distintas situaciones y conjuntos de datos. Pero en este cso veremos el más basico que podemos encontrar en el libro de optimización."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db5b3984-5f95-4ddb-8097-8e182327dc97",
      "metadata": {
        "id": "db5b3984-5f95-4ddb-8097-8e182327dc97"
      },
      "source": [
        "## Algoritmo\n",
        "\n",
        "Este es un metodo de primer orden, lo que significa que que se basa en la información del gradiente para poder encontrar un minimo, lo que significa que también nos ayudara a elegir la dirección hacia la cual movernos en una función.\n",
        "\n",
        "Primeramente para este metodo ocuparemos una dirección $d$ la cual es la cual indica la dirección de máximo descenso, lo cual nos garantiza una mejora, esto si la función es derivable y es continua en en su dominio, el paso es suficientemente pequeño y el gradiente no es 0, ya que se estaria en un punto estacionario.\n",
        "\n",
        "El gradiente es una generalización de las pendientes, y esta muestra la direcicón de máximo aumento, o crecimiento de una función, y el punto el gradiente descenciente es ir en dirección contraria al gradiente, por lo cual lo podemos definir como\n",
        "\n",
        "$$ d = -  \\nabla f(x^{k}) $$\n",
        "\n",
        "Donde $x^k$ es x en la $k$ itreación.  \n",
        "\n",
        "Pero también se normaliza dado nos esto nos permite tener un tamaño de paso consistente lo que hablando en terminos generales es un hecho benefactor para la convergencia, puesto que los pasos no se veran influenciados por la magnitud del gradiente.\n",
        "\n",
        "$$ d^{(k)} = - \\frac{g^{(k)}}{||g^{(k)}||} $$\n",
        "\n",
        "Ahora en cuanto al camino trazado al realizar un descenso este es irrgular, a grado de que al momento de elegir direcciones la actual contra la anterior seran ortogonales, y esto lo podemos de de la siguiente forma, mediante la optimización\n",
        "\n",
        "$$\\alpha = \\operatorname{argmin}_{\\alpha} f(x^{(k)} + \\alpha d^{(k)}) $$\n",
        "\n",
        "Donde buscamos un paso $\\alpha$ que minimice la función a cada paso, y dado que la dirección tambień se calcula a cada paso, es necesario buscar el tamaño de paso optimo a cada iteración.\n",
        "\n",
        "Pero esta optimización tiene un criterio a se cumnplido, para el cual necesitamos las dervadas direccionales.\n",
        "\n",
        "Estas nos ayuda a medir la taza de cambio de un desplazamiento en una función hacia una dirección, pero a diferencia de como se ha visto con limites, esta también puede ser calculada con el producto del gradiente por un vector unitario de  dirección.\n",
        "\n",
        "$$ \\nabla f(x^{(k)} + \\alpha d^{(k)})^Td^{(k)} = 0$$\n",
        "\n",
        "Ya ahora como sabemos que para sacar la siguiente dirección ocupariamos:\n",
        "\n",
        "$$ d^{(k+1)} = - \\frac{\\nabla f(x^{(k)} + \\alpha d^{(k)})}{||\\nabla f(x^{(k)} + \\alpha d^{(k)})||} $$\n",
        "\n",
        "Practicamente podriamos afirmar que las direcicónes $d^{(k+1)}$ y $d ^{(k)}$ son ortogonales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ead8d8-f6a1-4462-ae1e-35701a32c8ff",
      "metadata": {
        "id": "e5ead8d8-f6a1-4462-ae1e-35701a32c8ff"
      },
      "source": [
        "## Ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44530443-09d0-4144-9539-756957eed331",
      "metadata": {
        "scrolled": true,
        "id": "44530443-09d0-4144-9539-756957eed331",
        "outputId": "90486646-ef09-4016-bdb4-47ca3b330cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-3-76e5e3a0b6c2>, line 17)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-76e5e3a0b6c2>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    gf(x) = 2x\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        "# COmentario para probar\n",
        "\n",
        "using Plots\n",
        "\n",
        "abstract type\n",
        "    DescentMethod\n",
        "end\n",
        "\n",
        "struct GradientDescent <: DescentMethod\n",
        "    α\n",
        "end\n",
        "\n",
        "init!(M::GradientDescent, f, ∇f, x) = M\n",
        "\n",
        "# Modificar la función f para x^2\n",
        "f(x) = x^2\n",
        "\n",
        "# Modificar el gradiente de f para la función x^2 (2x)\n",
        "∇f(x) = 2x\n",
        "\n",
        "function step!(M::GradientDescent, f, ∇f, x)\n",
        "    α, g = M.α, ∇f(x)\n",
        "    return x - α*g\n",
        "end\n",
        "\n",
        "# Valor inicial de x y tasa de aprendizaje α\n",
        "x = 5.0\n",
        "α = 0.1\n",
        "\n",
        "# Número de iteraciones\n",
        "num_iteraciones = 2\n",
        "\n",
        "# Crear instancia de GradientDescent con la tasa de aprendizaje α\n",
        "gd = GradientDescent(α)\n",
        "\n",
        "# Almacenar los valores de x en cada iteración\n",
        "x_vals = [x]\n",
        "\n",
        "# Ejecutar múltiples pasos del algoritmo de descenso de gradiente\n",
        "for i in 1:num_iteraciones\n",
        "    x = step!(gd, f, ∇f, x)\n",
        "    push!(x_vals, x)\n",
        "end\n",
        "\n",
        "# Crear una gráfica de la función x^2\n",
        "plot(-10:0.1:10, x -> f(x), label=\"x^2\", xlabel=\"x\", ylabel=\"f(x)\", legend=:topleft)\n",
        "\n",
        "# Imprimir el último valor de x\n",
        "println(\"Último valor de x después del descenso de gradiente: \", x)\n",
        "\n",
        "# Agregar los puntos x en cada iteración\n",
        "scatter!(x_vals, map(f, x_vals), label=\"Descenso de gradiente\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.9.2",
      "language": "julia",
      "name": "julia-1.9"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.9.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}